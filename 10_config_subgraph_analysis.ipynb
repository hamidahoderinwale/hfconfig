{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Config Subgraph Analysis\n",
        "\n",
        "**Goal**: Analyze architectural similarity within descendant clusters (subgraphs) and drift along lineage paths.\n",
        "\n",
        "**Key Questions**:\n",
        "1. How architecturally coherent are descendant clusters?\n",
        "2. Do some families maintain architectural similarity better than others?\n",
        "3. How does config drift accumulate along lineage paths?\n",
        "4. Are architectures stable after the root, or do they drift continuously?\n",
        "\n",
        "**Contents**:\n",
        "- Subgraph similarity analysis (coherence within descendant clusters)\n",
        "- Config drift by depth in lineage trees\n",
        "- Cumulative drift along lineage paths\n",
        "- Family-level coherence comparisons\n",
        "\n",
        "**Dependencies**: Uses Gower distance function and requires family graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Style matching main repo\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config data\n",
        "df = pd.read_csv('data/model_configs_expanded.csv', low_memory=False)\n",
        "print(f\"Loaded {len(df):,} models with config.json\")\n",
        "print(f\"Total columns: {len(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup: Feature Preparation and Gower Distance\n",
        "\n",
        "**Note**: This section redefines the Gower distance function for self-contained execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define features and categorize (same as notebook 08/09)\n",
        "architecture_features = [\n",
        "    'config_model_type', 'config_hidden_size', 'config_num_hidden_layers',\n",
        "    'config_num_attention_heads', 'config_intermediate_size'\n",
        "]\n",
        "capacity_features = [\n",
        "    'config_vocab_size', 'config_max_position_embeddings', 'config_num_key_value_heads'\n",
        "]\n",
        "precision_features = [\n",
        "    'config_torch_dtype', 'config_rope_theta', 'config_rope_scaling_type'\n",
        "]\n",
        "boolean_features = ['uses_moe', 'uses_gqa', 'uses_rope', 'uses_quantization']\n",
        "\n",
        "all_features = architecture_features + capacity_features + precision_features + boolean_features\n",
        "available_features = [f for f in all_features if f in df.columns]\n",
        "\n",
        "# Categorize features\n",
        "numeric_features = []\n",
        "categorical_features = []\n",
        "boolean_feature_list = []\n",
        "\n",
        "for feat in available_features:\n",
        "    if feat in df.columns:\n",
        "        sample_values = df[feat].dropna().head(100)\n",
        "        if len(sample_values) == 0:\n",
        "            continue\n",
        "        try:\n",
        "            pd.to_numeric(sample_values, errors='raise')\n",
        "            numeric_features.append(feat)\n",
        "        except (ValueError, TypeError):\n",
        "            unique_vals = sample_values.unique()\n",
        "            if len(unique_vals) <= 2 and set(str(v).lower() for v in unique_vals).issubset({'true', 'false', '1', '0', 'yes', 'no', 'nan'}):\n",
        "                boolean_feature_list.append(feat)\n",
        "            else:\n",
        "                categorical_features.append(feat)\n",
        "\n",
        "print(f\"Features prepared: {len(available_features)} total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gower distance function\n",
        "def gower_distance(x, y, numeric_cols, categorical_cols, boolean_cols):\n",
        "    \"\"\"Compute Gower distance between two config vectors.\"\"\"\n",
        "    distance = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for col in numeric_cols:\n",
        "        if col in x.index and col in y.index:\n",
        "            x_val, y_val = x[col], y[col]\n",
        "            if pd.isna(x_val) or pd.isna(y_val):\n",
        "                continue\n",
        "            try:\n",
        "                x_num, y_num = float(x_val), float(y_val)\n",
        "                max_val = max(abs(x_num), abs(y_num))\n",
        "                if max_val > 0:\n",
        "                    distance += abs(x_num - y_num) / max_val\n",
        "                count += 1\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        if col in x.index and col in y.index:\n",
        "            x_val, y_val = x[col], y[col]\n",
        "            if pd.isna(x_val) or pd.isna(y_val):\n",
        "                continue\n",
        "            if str(x_val) != str(y_val):\n",
        "                distance += 1.0\n",
        "            count += 1\n",
        "    \n",
        "    for col in boolean_cols:\n",
        "        if col in x.index and col in y.index:\n",
        "            x_val, y_val = x[col], y[col]\n",
        "            if pd.isna(x_val) or pd.isna(y_val):\n",
        "                continue\n",
        "            x_bool = bool(x_val) if not pd.isna(x_val) else False\n",
        "            y_bool = bool(y_val) if not pd.isna(y_val) else False\n",
        "            if x_bool != y_bool:\n",
        "                distance += 1.0\n",
        "            count += 1\n",
        "    \n",
        "    return distance / count if count > 0 else 1.0\n",
        "\n",
        "print(\"✓ Gower distance function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Family Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prepare Config Features for Similarity Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze config similarity within subgraphs (descendant clusters)\n",
        "if G_family is not None:\n",
        "    print(\"Analyzing config similarity within descendant subgraphs...\")\n",
        "    \n",
        "    # Find root nodes (nodes with no incoming edges)\n",
        "    root_nodes = [n for n in G_family.nodes() if G_family.in_degree(n) == 0]\n",
        "    print(f\"Found {len(root_nodes):,} root nodes\")\n",
        "    \n",
        "    # Analyze top root nodes by number of descendants\n",
        "    root_descendant_counts = {}\n",
        "    for root in root_nodes[:min(20, len(root_nodes))]:  # Top 20 roots\n",
        "        descendants = set(nx.descendants(G_family, root))\n",
        "        root_descendant_counts[root] = len(descendants)\n",
        "    \n",
        "    # Sort by descendant count\n",
        "    top_roots = sorted(root_descendant_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    \n",
        "    subgraph_stats = []\n",
        "    \n",
        "    for root_id, n_descendants in top_roots:\n",
        "        if n_descendants < 5:  # Skip small subgraphs\n",
        "            continue\n",
        "        \n",
        "        # Get subgraph\n",
        "        descendants = set(nx.descendants(G_family, root_id)) | {root_id}\n",
        "        subgraph_nodes = [n for n in descendants if n in df['modelId'].values]\n",
        "        \n",
        "        if len(subgraph_nodes) < 5:\n",
        "            continue\n",
        "        \n",
        "        # Get config vectors for subgraph\n",
        "        subgraph_df = df[df['modelId'].isin(subgraph_nodes)][available_features].copy()\n",
        "        \n",
        "        if len(subgraph_df) < 2:\n",
        "            continue\n",
        "        \n",
        "        # Compute pairwise similarities within subgraph\n",
        "        subgraph_similarities = []\n",
        "        subgraph_indices = subgraph_df.index.tolist()\n",
        "        \n",
        "        for i in range(len(subgraph_indices)):\n",
        "            for j in range(i+1, len(subgraph_indices)):\n",
        "                vec_i = subgraph_df.loc[subgraph_indices[i]]\n",
        "                vec_j = subgraph_df.loc[subgraph_indices[j]]\n",
        "                \n",
        "                dist = gower_distance(\n",
        "                    vec_i, vec_j,\n",
        "                    numeric_features,\n",
        "                    categorical_features,\n",
        "                    boolean_feature_list\n",
        "                )\n",
        "                subgraph_similarities.append(1 - dist)\n",
        "        \n",
        "        if len(subgraph_similarities) > 0:\n",
        "            mean_sim = np.mean(subgraph_similarities)\n",
        "            median_sim = np.median(subgraph_similarities)\n",
        "            \n",
        "            # Get family info\n",
        "            root_family = df[df['modelId'] == root_id]['family'].iloc[0] if len(df[df['modelId'] == root_id]) > 0 else 'Unknown'\n",
        "            \n",
        "            subgraph_stats.append({\n",
        "                'root_id': root_id,\n",
        "                'n_nodes': len(subgraph_nodes),\n",
        "                'n_descendants': n_descendants,\n",
        "                'mean_similarity': mean_sim,\n",
        "                'median_similarity': median_sim,\n",
        "                'family': root_family\n",
        "            })\n",
        "    \n",
        "    df_subgraph_stats = pd.DataFrame(subgraph_stats)\n",
        "    \n",
        "    if len(df_subgraph_stats) > 0:\n",
        "        print(f\"\\\\n✓ Analyzed {len(df_subgraph_stats)} subgraphs\")\n",
        "        print(f\"\\\\nSubgraph similarity statistics:\")\n",
        "        print(df_subgraph_stats[['root_id', 'n_nodes', 'mean_similarity', 'family']].head(10).to_string(index=False))\n",
        "        \n",
        "        # Visualize\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Scatter: subgraph size vs similarity\n",
        "        axes[0].scatter(df_subgraph_stats['n_nodes'], df_subgraph_stats['mean_similarity'], \n",
        "                       alpha=0.6, s=100, c='steelblue')\n",
        "        axes[0].set_xlabel('Subgraph Size (Number of Nodes)', fontsize=11)\n",
        "        axes[0].set_ylabel('Mean Config Similarity', fontsize=11)\n",
        "        axes[0].set_title('Subgraph Size vs Config Similarity', fontsize=13)\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Similarity by family\n",
        "        if 'family' in df_subgraph_stats.columns and df_subgraph_stats['family'].nunique() > 1:\n",
        "            family_similarity = df_subgraph_stats.groupby('family')['mean_similarity'].agg(['mean', 'count']).sort_values('count', ascending=False).head(10)\n",
        "            \n",
        "            x_pos = np.arange(len(family_similarity))\n",
        "            axes[1].bar(x_pos, family_similarity['mean'], color='coral', alpha=0.7)\n",
        "            axes[1].set_xticks(x_pos)\n",
        "            axes[1].set_xticklabels(family_similarity.index, rotation=45, ha='right')\n",
        "            axes[1].set_ylabel('Mean Config Similarity', fontsize=11)\n",
        "            axes[1].set_title('Mean Subgraph Similarity by Family', fontsize=13)\n",
        "            axes[1].grid(True, alpha=0.3, axis='y')\n",
        "            \n",
        "            # Add count labels\n",
        "            for i, (idx, row) in enumerate(family_similarity.iterrows()):\n",
        "                axes[1].text(i, row['mean'] + 0.01, f\\\"n={int(row['count'])}\\\", ha='center', fontsize=8)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('figures/subgraph_similarity_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # Save subgraph stats\n",
        "        df_subgraph_stats.to_csv('subgraph_similarity_stats.csv', index=False)\n",
        "        print(\"\\\\n✓ Subgraph stats saved to subgraph_similarity_stats.csv\")\n",
        "    else:\n",
        "        print(\"No subgraph statistics computed\")\n",
        "else:\n",
        "    print(\"Family graph not available - skipping subgraph analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Drift by Depth: Config Drift Curves\n",
        "\n",
        "**Goal**: Measure cumulative config drift along lineage paths (root → ... → leaf), parallel to trait drift curves in the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze config drift by depth in lineage trees\n",
        "if G_family is not None:\n",
        "    print(\"Analyzing config drift by depth...\")\n",
        "    \n",
        "    # Find some deep lineages\n",
        "    def get_lineage_paths(root, max_depth=10, max_paths=100):\n",
        "        \\\"\\\"\\\"Get paths from root to leaves\\\"\\\"\\\"\n",
        "        paths = []\n",
        "        leaves = [n for n in G_family.nodes() if G_family.out_degree(n) == 0 and nx.has_path(G_family, root, n)]\n",
        "        \n",
        "        for leaf in leaves[:max_paths]:\n",
        "            try:\n",
        "                path = nx.shortest_path(G_family, root, leaf)\n",
        "                if len(path) <= max_depth:\n",
        "                    paths.append(path)\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        return paths\n",
        "    \n",
        "    # Analyze drift along paths for top roots\n",
        "    depth_drift_data = []\n",
        "    \n",
        "    for root_id, _ in top_roots[:5]:  # Top 5 roots\n",
        "        if root_id not in df['modelId'].values:\n",
        "            continue\n",
        "        \n",
        "        paths = get_lineage_paths(root_id, max_depth=8, max_paths=50)\n",
        "        \n",
        "        for path in paths:\n",
        "            # Filter to nodes with config data\n",
        "            path_with_config = [n for n in path if n in df['modelId'].values]\n",
        "            \n",
        "            if len(path_with_config) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Get root config\n",
        "            root_config = df[df['modelId'] == path_with_config[0]][available_features].iloc[0]\n",
        "            \n",
        "            # Compute cumulative drift along path\n",
        "            for i, node_id in enumerate(path_with_config[1:], 1):\n",
        "                node_config = df[df['modelId'] == node_id][available_features].iloc[0]\n",
        "                \n",
        "                drift = gower_distance(\n",
        "                    root_config, node_config,\n",
        "                    numeric_features,\n",
        "                    categorical_features,\n",
        "                    boolean_feature_list\n",
        "                )\n",
        "                \n",
        "                depth_drift_data.append({\n",
        "                    'root_id': root_id,\n",
        "                    'node_id': node_id,\n",
        "                    'depth': i,\n",
        "                    'cumulative_drift': drift,\n",
        "                    'path_length': len(path_with_config)\n",
        "                })\n",
        "    \n",
        "    df_depth_drift = pd.DataFrame(depth_drift_data)\n",
        "    \n",
        "    if len(df_depth_drift) > 0:\n",
        "        print(f\"\\\\n✓ Analyzed drift along {df_depth_drift['root_id'].nunique()} lineage trees\")\n",
        "        \n",
        "        # Visualize drift by depth\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Average drift by depth\n",
        "        depth_stats = df_depth_drift.groupby('depth')['cumulative_drift'].agg(['mean', 'median', 'std', 'count']).reset_index()\n",
        "        \n",
        "        axes[0].plot(depth_stats['depth'], depth_stats['mean'], marker='o', linewidth=2, label='Mean', color='steelblue')\n",
        "        axes[0].fill_between(depth_stats['depth'], \n",
        "                            depth_stats['mean'] - depth_stats['std'],\n",
        "                            depth_stats['mean'] + depth_stats['std'],\n",
        "                            alpha=0.2, color='steelblue')\n",
        "        axes[0].plot(depth_stats['depth'], depth_stats['median'], marker='s', linewidth=2, label='Median', color='coral', linestyle='--')\n",
        "        axes[0].set_xlabel('Depth in Lineage Tree', fontsize=11)\n",
        "        axes[0].set_ylabel('Cumulative Config Drift', fontsize=11)\n",
        "        axes[0].set_title('Config Drift vs Depth in Lineage Trees', fontsize=13)\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Distribution of drift at different depths\n",
        "        depth_samples = [1, 3, 5, 7]\n",
        "        available_depths = [d for d in depth_samples if d in df_depth_drift['depth'].values]\n",
        "        \n",
        "        if len(available_depths) > 0:\n",
        "            drift_by_depth = [df_depth_drift[df_depth_drift['depth'] == d]['cumulative_drift'].values for d in available_depths]\n",
        "            axes[1].boxplot(drift_by_depth, labels=[f'Depth {d}' for d in available_depths])\n",
        "            axes[1].set_xlabel('Depth', fontsize=11)\n",
        "            axes[1].set_ylabel('Cumulative Config Drift', fontsize=11)\n",
        "            axes[1].set_title('Distribution of Config Drift at Different Depths', fontsize=13)\n",
        "            axes[1].grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('figures/drift_by_depth.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # Save depth drift data\n",
        "        df_depth_drift.to_csv('config_drift_by_depth.csv', index=False)\n",
        "        print(\"\\\\n✓ Depth drift data saved to config_drift_by_depth.csv\")\n",
        "    else:\n",
        "        print(\"No depth drift data computed\")\n",
        "else:\n",
        "    print(\"Family graph not available - skipping depth analysis\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
