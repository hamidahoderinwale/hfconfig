{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# S-Curve Analysis: Architectural Feature Diffusion Over Time\n",
        "\n",
        "**Goal**: Track how architectural innovations diffuse across the Hugging Face ecosystem over time.\n",
        "\n",
        "**Core Question**: How do certain architectural innovations diffuse over time across the Hugging Face ecosystem?\n",
        "\n",
        "**Key Features to Track**:\n",
        "1. **torch_dtype**: fp16, bf16, fp32, 4-bit, 8-bit quantization\n",
        "2. **max_position_embeddings**: Context length expansions (â‰¥8k, â‰¥32k, â‰¥128k)\n",
        "3. **num_key_value_heads**: Grouped-query attention (GQA/MQA) adoption\n",
        "4. **transformers_version**: Proxy for library-era / feature availability\n",
        "\n",
        "**Analysis**:\n",
        "- Fraction of new models per month adopting each feature\n",
        "- Compare across task tags (LLM vs vision vs audio) or licenses\n",
        "- Identify S-curve patterns of diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Style matching main repo\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config data\n",
        "df_configs = pd.read_csv('data/model_configs_expanded.csv', low_memory=False)\n",
        "print(f\"Loaded {len(df_configs):,} models with config.json\")\n",
        "\n",
        "# Load main dataset for timestamps and metadata\n",
        "# Try to load from HuggingFace dataset (modelbiome/ai_ecosystem), fallback on local CSVs if datasets lib missing\n",
        "print(\"Loading from HuggingFace dataset (modelbiome/ai_ecosystem)...\")\n",
        "\n",
        "try:\n",
        "    from datasets import load_dataset\n",
        "    DATASETS_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    print(\"ModuleNotFoundError: No module named 'datasets'\")\n",
        "    DATASETS_AVAILABLE = False\n",
        "\n",
        "if DATASETS_AVAILABLE:\n",
        "    try:\n",
        "        dataset = load_dataset(\"modelbiome/ai_ecosystem\", split=\"train\")\n",
        "        print(f\"Dataset loaded with {len(dataset):,} models\")\n",
        "        print(f\"Available columns: {dataset.column_names[:15]}...\")\n",
        "        \n",
        "        # Build DataFrame column by column, checking if each exists\n",
        "        data_dict = {'modelId': dataset['model_id']}\n",
        "        \n",
        "        # Map of desired column names to possible dataset column names\n",
        "        col_mapping = {\n",
        "            'createdAt': ['createdAt', 'created_at'],\n",
        "            'downloads': ['downloads'],\n",
        "            'likes': ['likes'],\n",
        "            'pipeline_tag': ['pipeline_tag', 'pipelineTag']\n",
        "        }\n",
        "        \n",
        "        for target_col, possible_cols in col_mapping.items():\n",
        "            found = False\n",
        "            for possible_col in possible_cols:\n",
        "                if possible_col in dataset.column_names:\n",
        "                    data_dict[target_col] = dataset[possible_col]\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                # Set default values\n",
        "                if target_col == 'createdAt' or target_col == 'pipeline_tag':\n",
        "                    data_dict[target_col] = [None] * len(dataset)\n",
        "                else:\n",
        "                    data_dict[target_col] = [0] * len(dataset)\n",
        "        \n",
        "        df_main = pd.DataFrame(data_dict)\n",
        "        print(f\"Loaded {len(df_main):,} models from HuggingFace\")\n",
        "        print(f\"Columns in df_main: {df_main.columns.tolist()}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading from HuggingFace: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nTrying alternative: load from expanded dataset if available...\")\n",
        "        DATASETS_AVAILABLE = False  # fallback below\n",
        "\n",
        "if not DATASETS_AVAILABLE:\n",
        "    # Try to find an expanded dataset CSV\n",
        "    try:\n",
        "        import os\n",
        "        alt_paths = [\n",
        "            'data/ai_ecosystem_expanded.csv',\n",
        "            'data/ai_ecosystem.csv',\n",
        "            '../ai_ecosystem.csv'\n",
        "        ]\n",
        "        found = False\n",
        "        for path in alt_paths:\n",
        "            if os.path.exists(path):\n",
        "                df_main = pd.read_csv(path, low_memory=False)\n",
        "                if 'modelId' not in df_main.columns and 'model_id' in df_main.columns:\n",
        "                    df_main['modelId'] = df_main['model_id']\n",
        "                # Ensure required columns exist\n",
        "                for col in ['createdAt', 'downloads', 'likes', 'pipeline_tag']:\n",
        "                    if col not in df_main.columns:\n",
        "                        df_main[col] = None if col in ['createdAt', 'pipeline_tag'] else 0\n",
        "                print(f\"Loaded {len(df_main):,} models from {path}\")\n",
        "                found = True\n",
        "                break\n",
        "        \n",
        "        if not found:\n",
        "            # Last resort: create minimal dataframe\n",
        "            df_main = pd.DataFrame({'modelId': df_configs['modelId']})\n",
        "            df_main['createdAt'] = None\n",
        "            df_main['downloads'] = 0\n",
        "            df_main['likes'] = 0\n",
        "            df_main['pipeline_tag'] = None\n",
        "            print(\"Created minimal dataframe - time-based analysis will be limited\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Error in fallback: {e2}\")\n",
        "        df_main = pd.DataFrame({'modelId': df_configs['modelId']})\n",
        "        df_main['createdAt'] = None\n",
        "        df_main['downloads'] = 0\n",
        "        df_main['likes'] = 0\n",
        "        df_main['pipeline_tag'] = None\n",
        "\n",
        "# Join configs with main dataset - only use columns that exist\n",
        "cols_to_merge = ['modelId']\n",
        "for col in ['createdAt', 'downloads', 'likes', 'pipeline_tag']:\n",
        "    if col in df_main.columns:\n",
        "        cols_to_merge.append(col)\n",
        "\n",
        "df = df_configs.merge(df_main[cols_to_merge], on='modelId', how='left')\n",
        "print(f\"\\nJoined dataset: {len(df):,} models with both config and metadata\")\n",
        "if 'createdAt' in df.columns:\n",
        "    print(f\"Models with createdAt: {df['createdAt'].notna().sum():,}\")\n",
        "else:\n",
        "    print(\"Warning: createdAt column not available - time-based analysis will be limited\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse createdAt timestamps\n",
        "def parse_date(date_str):\n",
        "    if pd.isna(date_str):\n",
        "        return None\n",
        "    try:\n",
        "        return pd.to_datetime(date_str)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df['created_date'] = df['createdAt'].apply(parse_date)\n",
        "df['year_month'] = df['created_date'].dt.to_period('M')\n",
        "\n",
        "# Filter to models with valid dates\n",
        "df_dated = df[df['created_date'].notna()].copy()\n",
        "print(f\"Models with valid dates: {len(df_dated):,}\")\n",
        "print(f\"Date range: {df_dated['created_date'].min()} to {df_dated['created_date'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Torch Dtype Adoption Over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorize torch_dtype\n",
        "def categorize_dtype(dtype_str):\n",
        "    if pd.isna(dtype_str):\n",
        "        return 'unknown'\n",
        "    dtype_str = str(dtype_str).lower()\n",
        "    if 'bfloat16' in dtype_str or 'bf16' in dtype_str:\n",
        "        return 'bf16'\n",
        "    elif 'float16' in dtype_str or 'fp16' in dtype_str:\n",
        "        return 'fp16'\n",
        "    elif 'float32' in dtype_str or 'fp32' in dtype_str:\n",
        "        return 'fp32'\n",
        "    elif 'int4' in dtype_str or '4-bit' in dtype_str:\n",
        "        return '4-bit'\n",
        "    elif 'int8' in dtype_str or '8-bit' in dtype_str:\n",
        "        return '8-bit'\n",
        "    else:\n",
        "        return 'other'\n",
        "\n",
        "df_dated['dtype_category'] = df_dated['config_torch_dtype'].apply(categorize_dtype)\n",
        "\n",
        "# Calculate monthly adoption rates\n",
        "monthly_stats = df_dated.groupby('year_month').agg({\n",
        "    'modelId': 'count',\n",
        "    'dtype_category': lambda x: x.value_counts().to_dict()\n",
        "}).reset_index()\n",
        "monthly_stats.columns = ['year_month', 'total_models', 'dtype_counts']\n",
        "\n",
        "# Extract adoption rates for each dtype\n",
        "dtype_types = ['bf16', 'fp16', 'fp32', '4-bit', '8-bit']\n",
        "for dtype in dtype_types:\n",
        "    monthly_stats[f'{dtype}_count'] = monthly_stats['dtype_counts'].apply(\n",
        "        lambda x: x.get(dtype, 0) if isinstance(x, dict) else 0\n",
        "    )\n",
        "    monthly_stats[f'{dtype}_rate'] = monthly_stats[f'{dtype}_count'] / monthly_stats['total_models'] * 100\n",
        "\n",
        "# Plot S-curves\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "for dtype in dtype_types:\n",
        "    if monthly_stats[f'{dtype}_count'].sum() > 0:\n",
        "        ax.plot(monthly_stats['year_month'].astype(str), monthly_stats[f'{dtype}_rate'], \n",
        "                marker='o', markersize=3, label=f'{dtype.upper()}', linewidth=2, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Adoption Rate (% of new models)')\n",
        "ax.set_title('Torch Dtype Adoption Over Time (S-Curve)', fontsize=14)\n",
        "ax.legend(loc='best')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/scurve_dtype_adoption.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Context Length Expansion Over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorize context lengths\n",
        "df_dated['max_pos'] = pd.to_numeric(df_dated['config_max_position_embeddings'], errors='coerce')\n",
        "\n",
        "df_dated['ctx_8k'] = (df_dated['max_pos'] >= 8192).astype(int)\n",
        "df_dated['ctx_32k'] = (df_dated['max_pos'] >= 32768).astype(int)\n",
        "df_dated['ctx_128k'] = (df_dated['max_pos'] >= 131072).astype(int)\n",
        "\n",
        "# Monthly adoption rates\n",
        "ctx_monthly = df_dated.groupby('year_month').agg({\n",
        "    'modelId': 'count',\n",
        "    'ctx_8k': 'sum',\n",
        "    'ctx_32k': 'sum',\n",
        "    'ctx_128k': 'sum'\n",
        "}).reset_index()\n",
        "ctx_monthly.columns = ['year_month', 'total', 'count_8k', 'count_32k', 'count_128k']\n",
        "\n",
        "ctx_monthly['rate_8k'] = ctx_monthly['count_8k'] / ctx_monthly['total'] * 100\n",
        "ctx_monthly['rate_32k'] = ctx_monthly['count_32k'] / ctx_monthly['total'] * 100\n",
        "ctx_monthly['rate_128k'] = ctx_monthly['count_128k'] / ctx_monthly['total'] * 100\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "ax.plot(ctx_monthly['year_month'].astype(str), ctx_monthly['rate_8k'], \n",
        "        marker='o', markersize=3, label='â‰¥8K context', linewidth=2, alpha=0.8)\n",
        "ax.plot(ctx_monthly['year_month'].astype(str), ctx_monthly['rate_32k'], \n",
        "        marker='s', markersize=3, label='â‰¥32K context', linewidth=2, alpha=0.8)\n",
        "ax.plot(ctx_monthly['year_month'].astype(str), ctx_monthly['rate_128k'], \n",
        "        marker='^', markersize=3, label='â‰¥128K context', linewidth=2, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Adoption Rate (% of new models)')\n",
        "ax.set_title('Context Length Expansion Over Time', fontsize=14)\n",
        "ax.legend(loc='best')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/scurve_context_length.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Grouped-Query Attention (GQA) Adoption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect GQA/MQA (num_key_value_heads < num_attention_heads)\n",
        "df_dated['num_heads'] = pd.to_numeric(df_dated['config_num_attention_heads'], errors='coerce')\n",
        "df_dated['num_kv_heads'] = pd.to_numeric(df_dated['config_num_key_value_heads'], errors='coerce')\n",
        "\n",
        "# GQA: num_kv_heads exists and is less than num_attention_heads\n",
        "df_dated['uses_gqa'] = (\n",
        "    (df_dated['num_kv_heads'].notna()) & \n",
        "    (df_dated['num_heads'].notna()) &\n",
        "    (df_dated['num_kv_heads'] < df_dated['num_heads'])\n",
        ").astype(int)\n",
        "\n",
        "# Monthly adoption\n",
        "gqa_monthly = df_dated.groupby('year_month').agg({\n",
        "    'modelId': 'count',\n",
        "    'uses_gqa': 'sum'\n",
        "}).reset_index()\n",
        "gqa_monthly.columns = ['year_month', 'total', 'gqa_count']\n",
        "gqa_monthly['gqa_rate'] = gqa_monthly['gqa_count'] / gqa_monthly['total'] * 100\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "ax.plot(gqa_monthly['year_month'].astype(str), gqa_monthly['gqa_rate'], \n",
        "        marker='o', markersize=4, label='GQA/MQA', linewidth=2.5, color='#2E86AB')\n",
        "\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Adoption Rate (% of new models)')\n",
        "ax.set_title('Grouped-Query Attention (GQA) Adoption Over Time', fontsize=14)\n",
        "ax.legend(loc='best')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/scurve_gqa_adoption.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Transformers Version Evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract major.minor version\n",
        "def extract_version(version_str):\n",
        "    if pd.isna(version_str):\n",
        "        return None\n",
        "    try:\n",
        "        parts = str(version_str).split('.')\n",
        "        if len(parts) >= 2:\n",
        "            return f\"{parts[0]}.{parts[1]}\"\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "df_dated['transformers_major_minor'] = df_dated['config_transformers_version'].apply(extract_version)\n",
        "\n",
        "# Top versions\n",
        "top_versions = df_dated['transformers_major_minor'].value_counts().head(10).index.tolist()\n",
        "\n",
        "# Monthly adoption by version\n",
        "version_monthly = df_dated[df_dated['transformers_major_minor'].isin(top_versions)].groupby(\n",
        "    ['year_month', 'transformers_major_minor']\n",
        ").size().unstack(fill_value=0)\n",
        "\n",
        "# Calculate rates\n",
        "monthly_totals = df_dated.groupby('year_month').size()\n",
        "version_monthly_pct = version_monthly.div(monthly_totals, axis=0) * 100\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "for version in top_versions[:6]:  # Top 6 versions\n",
        "    if version in version_monthly_pct.columns:\n",
        "        ax.plot(version_monthly_pct.index.astype(str), version_monthly_pct[version], \n",
        "                marker='o', markersize=3, label=f'v{version}', linewidth=2, alpha=0.7)\n",
        "\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Adoption Rate (% of new models)')\n",
        "ax.set_title('Transformers Library Version Adoption Over Time', fontsize=14)\n",
        "ax.legend(loc='best', ncol=2)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/scurve_transformers_version.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comparison by Task Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare GQA adoption by pipeline_tag\n",
        "task_types = ['text-generation', 'image-to-image', 'image-classification', 'automatic-speech-recognition']\n",
        "df_task = df_dated[df_dated['pipeline_tag'].isin(task_types)].copy()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, task in enumerate(task_types[:4]):\n",
        "    task_df = df_task[df_task['pipeline_tag'] == task]\n",
        "    if len(task_df) > 0:\n",
        "        task_monthly = task_df.groupby('year_month').agg({\n",
        "            'modelId': 'count',\n",
        "            'uses_gqa': 'sum'\n",
        "        }).reset_index()\n",
        "        task_monthly['gqa_rate'] = task_monthly['uses_gqa'] / task_monthly['modelId'] * 100\n",
        "        \n",
        "        axes[idx].plot(task_monthly['year_month'].astype(str), task_monthly['gqa_rate'], \n",
        "                      marker='o', markersize=3, linewidth=2, color='#2E86AB')\n",
        "        axes[idx].set_title(f'{task.replace(\"-\", \" \").title()}', )\n",
        "        axes[idx].set_ylabel('GQA Adoption Rate (%)')\n",
        "        axes[idx].grid(True, alpha=0.3)\n",
        "        axes[idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.suptitle('GQA Adoption by Task Type', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/scurve_gqa_by_task.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Combined S-Curve Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive S-curve plot\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "# Normalize all rates to 0-100% scale\n",
        "features_to_plot = [\n",
        "    ('bf16', monthly_stats['bf16_rate'], '#FF6B6B'),\n",
        "    ('fp16', monthly_stats['fp16_rate'], '#4ECDC4'),\n",
        "    ('GQA', gqa_monthly['gqa_rate'], '#2E86AB'),\n",
        "    ('â‰¥32K context', ctx_monthly['rate_32k'], '#A23B72'),\n",
        "    ('â‰¥128K context', ctx_monthly['rate_128k'], '#F18F01')\n",
        "]\n",
        "\n",
        "for name, rates, color in features_to_plot:\n",
        "    if len(rates) > 0 and rates.max() > 0:\n",
        "        if name == 'GQA':\n",
        "            x_vals = gqa_monthly['year_month'].astype(str)\n",
        "        elif 'context' in name:\n",
        "            x_vals = ctx_monthly['year_month'].astype(str)\n",
        "        else:\n",
        "            x_vals = monthly_stats['year_month'].astype(str)\n",
        "        \n",
        "        ax.plot(x_vals, rates, marker='o', markersize=4, label=name, \n",
        "                linewidth=2.5, color=color, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Month', fontsize=12)\n",
        "ax.set_ylabel('Adoption Rate (% of new models)', fontsize=12)\n",
        "ax.set_title('Architectural Feature Diffusion: S-Curves Over Time', fontsize=16)\n",
        "ax.legend(loc='best', fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/scurve_comprehensive.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nðŸ“ˆ Feature Adoption Summary:\")\n",
        "print(f\"   BF16: Peak adoption {monthly_stats['bf16_rate'].max():.1f}%\")\n",
        "print(f\"   FP16: Peak adoption {monthly_stats['fp16_rate'].max():.1f}%\")\n",
        "print(f\"   GQA: Peak adoption {gqa_monthly['gqa_rate'].max():.1f}%\")\n",
        "print(f\"   â‰¥32K context: Peak adoption {ctx_monthly['rate_32k'].max():.1f}%\")\n",
        "print(f\"   â‰¥128K context: Peak adoption {ctx_monthly['rate_128k'].max():.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
