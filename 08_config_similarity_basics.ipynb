{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Similarity Basics\n",
    "\n",
    "**Goal**: Core similarity computation and graph construction for config-based architectural similarity.\n",
    "\n",
    "**Key Questions**:\n",
    "1. Which models are architecturally similar?\n",
    "2. How do models cluster in architecture space?\n",
    "3. What are the nearest neighbors in architecture space?\n",
    "4. How do different similarity metrics compare?\n",
    "\n",
    "**Contents**:\n",
    "- Feature preparation and categorization\n",
    "- Gower distance implementation (handles mixed data types)\n",
    "- Similarity matrix computation\n",
    "- Similarity graph construction\n",
    "- Graph visualization and statistics\n",
    "- Nearest neighbors analysis\n",
    "- Similarity metrics comparison (Gower, L2, L1, Cosine)\n",
    "\n",
    "**This is the foundational notebook** - other notebooks build on these utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style matching main repo\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create figures directory if it doesn't exist\n",
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config data\n",
    "df = pd.read_csv('../data/model_configs_expanded.csv', low_memory=False)\n",
    "print(f\"Loaded {len(df):,} models with config.json\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "\n",
    "# Ensure modelId column exists\n",
    "if 'modelId' not in df.columns:\n",
    "    raise ValueError(\"modelId column not found in dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Config Features for Similarity Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups for similarity computation\n",
    "\n",
    "# Core architecture features (high weight)\n",
    "architecture_features = [\n",
    "    'config_model_type',\n",
    "    'config_hidden_size',\n",
    "    'config_num_hidden_layers',\n",
    "    'config_num_attention_heads',\n",
    "    'config_intermediate_size'\n",
    "]\n",
    "\n",
    "# Capacity features (medium weight)\n",
    "capacity_features = [\n",
    "    'config_vocab_size',\n",
    "    'config_max_position_embeddings',\n",
    "    'config_num_key_value_heads'\n",
    "]\n",
    "\n",
    "# Precision/compute features (lower weight)\n",
    "precision_features = [\n",
    "    'config_torch_dtype',\n",
    "    'config_rope_theta',\n",
    "    'config_rope_scaling_type'\n",
    "]\n",
    "\n",
    "# Boolean flags (low weight)\n",
    "boolean_features = [\n",
    "    'uses_moe',\n",
    "    'uses_gqa',\n",
    "    'uses_rope',\n",
    "    'uses_quantization'\n",
    "]\n",
    "\n",
    "# All features for similarity\n",
    "all_features = architecture_features + capacity_features + precision_features + boolean_features\n",
    "\n",
    "# Filter to features that exist in dataframe\n",
    "available_features = [f for f in all_features if f in df.columns]\n",
    "print(f\"Available features for similarity: {len(available_features)}\")\n",
    "print(f\"Features: {available_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorize Features by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features by data type for Gower distance computation\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "boolean_feature_list = []\n",
    "\n",
    "for feat in available_features:\n",
    "    if feat not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    # Check data type using sample values\n",
    "    sample_values = df[feat].dropna().head(100)\n",
    "    \n",
    "    if len(sample_values) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Try to convert to numeric\n",
    "    try:\n",
    "        pd.to_numeric(sample_values, errors='raise')\n",
    "        numeric_features.append(feat)\n",
    "    except (ValueError, TypeError):\n",
    "        # Check if boolean-like\n",
    "        unique_vals = sample_values.unique()\n",
    "        unique_strs = set(str(v).lower() for v in unique_vals if pd.notna(v))\n",
    "        \n",
    "        if len(unique_vals) <= 2 and unique_strs.issubset({'true', 'false', '1', '0', 'yes', 'no', 'nan'}):\n",
    "            boolean_feature_list.append(feat)\n",
    "        else:\n",
    "            categorical_features.append(feat)\n",
    "\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"\\nBoolean features ({len(boolean_feature_list)}): {boolean_feature_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement Gower Distance Function\n",
    "\n",
    "Gower distance handles mixed data types (numeric, categorical, boolean) and is ideal for config.json similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gower_distance(x, y, numeric_cols, categorical_cols, boolean_cols):\n",
    "    \"\"\"\n",
    "    Compute Gower distance between two config vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x, y : pandas Series\n",
    "        Config vectors to compare\n",
    "    numeric_cols : list\n",
    "        List of numeric feature column names\n",
    "    categorical_cols : list\n",
    "        List of categorical feature column names\n",
    "    boolean_cols : list\n",
    "        List of boolean feature column names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Gower distance (0 = identical, 1 = completely different)\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    - Numeric: normalized absolute difference\n",
    "    - Categorical: 0 if same, 1 if different\n",
    "    - Boolean: 0 if same, 1 if different\n",
    "    - Missing values: ignored in that dimension\n",
    "    \"\"\"\n",
    "    distance = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    # Numeric features: normalized absolute difference\n",
    "    for col in numeric_cols:\n",
    "        if col in x.index and col in y.index:\n",
    "            x_val = x[col]\n",
    "            y_val = y[col]\n",
    "            \n",
    "            # Skip if either is missing\n",
    "            if pd.isna(x_val) or pd.isna(y_val):\n",
    "                continue\n",
    "            \n",
    "            # Convert to numeric\n",
    "            try:\n",
    "                x_num = float(x_val)\n",
    "                y_num = float(y_val)\n",
    "                \n",
    "                # Normalized difference (using max value for normalization)\n",
    "                max_val = max(abs(x_num), abs(y_num))\n",
    "                if max_val > 0:\n",
    "                    distance += abs(x_num - y_num) / max_val\n",
    "                else:\n",
    "                    distance += 0  # Both are 0\n",
    "                count += 1\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "    \n",
    "    # Categorical features: 0 if same, 1 if different\n",
    "    for col in categorical_cols:\n",
    "        if col in x.index and col in y.index:\n",
    "            x_val = x[col]\n",
    "            y_val = y[col]\n",
    "            \n",
    "            # Skip if either is missing\n",
    "            if pd.isna(x_val) or pd.isna(y_val):\n",
    "                continue\n",
    "            \n",
    "            # Compare as strings\n",
    "            if str(x_val) != str(y_val):\n",
    "                distance += 1.0\n",
    "            count += 1\n",
    "    \n",
    "    # Boolean features: 0 if same, 1 if different\n",
    "    for col in boolean_cols:\n",
    "        if col in x.index and col in y.index:\n",
    "            x_val = x[col]\n",
    "            y_val = y[col]\n",
    "            \n",
    "            # Skip if either is missing\n",
    "            if pd.isna(x_val) or pd.isna(y_val):\n",
    "                continue\n",
    "            \n",
    "            # Normalize boolean values\n",
    "            x_bool = bool(x_val) if not pd.isna(x_val) else False\n",
    "            y_bool = bool(y_val) if not pd.isna(y_val) else False\n",
    "            \n",
    "            if x_bool != y_bool:\n",
    "                distance += 1.0\n",
    "            count += 1\n",
    "    \n",
    "    # Return average distance (0 = identical, 1 = completely different)\n",
    "    if count > 0:\n",
    "        return distance / count\n",
    "    else:\n",
    "        return 1.0  # No common features = maximum distance\n",
    "\n",
    "print(\"✓ Gower distance function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Data for MVP\n",
    "\n",
    "For computational efficiency, we sample a subset of models. Increase SAMPLE_SIZE for more comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to models with at least some key features\n",
    "key_features = ['config_hidden_size', 'config_num_hidden_layers', 'config_model_type']\n",
    "df_complete = df[df[key_features].notna().any(axis=1)].copy()\n",
    "\n",
    "# Sample for MVP (can increase later)\n",
    "SAMPLE_SIZE = 1000  # Start with 1000 models for MVP\n",
    "\n",
    "if len(df_complete) > SAMPLE_SIZE:\n",
    "    # Stratified sample by family if available\n",
    "    if 'family' in df_complete.columns and df_complete['family'].notna().sum() > 0:\n",
    "        df_sample = df_complete.groupby('family', group_keys=False).apply(\n",
    "            lambda x: x.sample(min(len(x), max(1, SAMPLE_SIZE // df_complete['family'].nunique())), random_state=42)\n",
    "        ).head(SAMPLE_SIZE)\n",
    "    else:\n",
    "        df_sample = df_complete.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "else:\n",
    "    df_sample = df_complete.copy()\n",
    "\n",
    "# Reset index for easier indexing\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "\n",
    "print(f\"Sampled {len(df_sample):,} models for similarity computation\")\n",
    "print(f\"This will compute {len(df_sample) * (len(df_sample) - 1) // 2:,} pairwise distances\")\n",
    "\n",
    "# Verify we have the required columns\n",
    "if 'modelId' not in df_sample.columns:\n",
    "    raise ValueError(\"modelId column not found in sampled dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Similarity Matrix\n",
    "\n",
    "Compute pairwise Gower distances between all sampled models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise similarity matrix using Gower distance\n",
    "print(\"Computing similarity matrix...\")\n",
    "print(f\"Processing {len(df_sample):,} models...\")\n",
    "\n",
    "n_models = len(df_sample)\n",
    "similarity_matrix = np.zeros((n_models, n_models))\n",
    "\n",
    "# Compute pairwise distances\n",
    "for i in range(n_models):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"  Processed {i}/{n_models} models...\")\n",
    "    \n",
    "    for j in range(i+1, n_models):\n",
    "        vec_i = df_sample.iloc[i][available_features]\n",
    "        vec_j = df_sample.iloc[j][available_features]\n",
    "        \n",
    "        # Compute Gower distance\n",
    "        distance = gower_distance(\n",
    "            vec_i, vec_j,\n",
    "            numeric_features,\n",
    "            categorical_features,\n",
    "            boolean_feature_list\n",
    "        )\n",
    "        \n",
    "        # Store in symmetric matrix\n",
    "        similarity_matrix[i, j] = distance\n",
    "        similarity_matrix[j, i] = distance\n",
    "\n",
    "# Diagonal is 0 (self-similarity)\n",
    "np.fill_diagonal(similarity_matrix, 0.0)\n",
    "\n",
    "print(f\"\\n✓ Computed similarity matrix: {n_models}x{n_models}\")\n",
    "print(f\"  Mean distance: {similarity_matrix[similarity_matrix > 0].mean():.3f}\")\n",
    "print(f\"  Median distance: {np.median(similarity_matrix[similarity_matrix > 0]):.3f}\")\n",
    "print(f\"  Min distance: {similarity_matrix[similarity_matrix > 0].min():.3f}\")\n",
    "print(f\"  Max distance: {similarity_matrix[similarity_matrix > 0].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Similarity Graph\n",
    "\n",
    "Construct a graph where edges connect architecturally similar models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build similarity graph\n",
    "# Connect models that are architecturally similar (distance below threshold)\n",
    "\n",
    "# Use median distance as threshold (or top-k nearest neighbors)\n",
    "distance_threshold = np.median(similarity_matrix[similarity_matrix > 0])\n",
    "# Alternative: connect to top-k nearest neighbors\n",
    "K_NEAREST = 5  # Each model connects to its 5 most similar neighbors\n",
    "\n",
    "print(f\"Building similarity graph...\")\n",
    "print(f\"  Distance threshold: {distance_threshold:.3f}\")\n",
    "print(f\"  K-nearest neighbors: {K_NEAREST}\")\n",
    "\n",
    "G_similarity = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for idx, row in df_sample.iterrows():\n",
    "    G_similarity.add_node(row['modelId'], **row.to_dict())\n",
    "\n",
    "# Add edges based on similarity\n",
    "edges_added = 0\n",
    "for i in range(n_models):\n",
    "    model_i = df_sample.iloc[i]['modelId']\n",
    "    \n",
    "    # Get distances to all other models\n",
    "    distances = similarity_matrix[i, :]\n",
    "    \n",
    "    # Find k nearest neighbors (excluding self)\n",
    "    nearest_indices = np.argsort(distances)[1:K_NEAREST+1]  # Skip index 0 (self)\n",
    "    \n",
    "    for j in nearest_indices:\n",
    "        model_j = df_sample.iloc[j]['modelId']\n",
    "        distance = distances[j]\n",
    "        \n",
    "        # Add edge if below threshold\n",
    "        if distance <= distance_threshold:\n",
    "            G_similarity.add_edge(model_i, model_j, weight=1-distance, distance=distance)\n",
    "            edges_added += 1\n",
    "\n",
    "print(f\"\\n✓ Built similarity graph:\")\n",
    "print(f\"  Nodes: {len(G_similarity.nodes):,}\")\n",
    "print(f\"  Edges: {len(G_similarity.edges):,}\")\n",
    "if len(G_similarity.nodes) > 0:\n",
    "    print(f\"  Average degree: {2*len(G_similarity.edges)/len(G_similarity.nodes):.2f}\")\n",
    "    print(f\"  Connected components: {nx.number_connected_components(G_similarity)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Similarity Clusters\n",
    "\n",
    "Visualize the similarity graph and identify architectural clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity graph using network layout\n",
    "if len(G_similarity.nodes) > 0:\n",
    "    print(\"Computing graph layout...\")\n",
    "    \n",
    "    # Use spring layout for visualization\n",
    "    pos = nx.spring_layout(G_similarity, k=1, iterations=50, seed=42)\n",
    "    \n",
    "    # Get node colors by family if available\n",
    "    if 'family' in df_sample.columns and df_sample['family'].notna().sum() > 0:\n",
    "        families = df_sample.set_index('modelId')['family'].to_dict()\n",
    "        unique_families = df_sample['family'].dropna().unique()\n",
    "        family_colors = plt.cm.tab20(np.linspace(0, 1, len(unique_families)))\n",
    "        family_color_map = dict(zip(unique_families, family_colors))\n",
    "        node_colors = [family_color_map.get(families.get(node, 'Unknown'), 'gray') for node in G_similarity.nodes()]\n",
    "    else:\n",
    "        node_colors = 'steelblue'\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Left: Full graph\n",
    "    nx.draw(G_similarity, pos, ax=axes[0], \n",
    "            node_color=node_colors, \n",
    "            node_size=30, \n",
    "            edge_color='gray', \n",
    "            alpha=0.6,\n",
    "            with_labels=False,\n",
    "            width=0.5)\n",
    "    axes[0].set_title(f'Similarity Graph ({len(G_similarity.nodes):,} nodes, {len(G_similarity.edges):,} edges)', fontsize=13)\n",
    "    \n",
    "    # Right: Largest connected component\n",
    "    if nx.number_connected_components(G_similarity) > 0:\n",
    "        largest_cc = max(nx.connected_components(G_similarity), key=len)\n",
    "        G_largest = G_similarity.subgraph(largest_cc).copy()\n",
    "        \n",
    "        if len(G_largest.nodes) > 0:\n",
    "            pos_largest = nx.spring_layout(G_largest, k=1, iterations=50, seed=42)\n",
    "            if isinstance(node_colors, list):\n",
    "                node_colors_largest = [node_colors[list(G_similarity.nodes).index(node)] for node in G_largest.nodes]\n",
    "            else:\n",
    "                node_colors_largest = node_colors\n",
    "            \n",
    "            nx.draw(G_largest, pos_largest, ax=axes[1],\n",
    "                   node_color=node_colors_largest,\n",
    "                   node_size=50,\n",
    "                   edge_color='gray',\n",
    "                   alpha=0.7,\n",
    "                   with_labels=False,\n",
    "                   width=0.8)\n",
    "            axes[1].set_title(f'Largest Connected Component ({len(G_largest.nodes):,} nodes)', fontsize=13)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/similarity_graph.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Graph statistics\n",
    "    print(f\"\\nGraph Statistics:\")\n",
    "    print(f\"  Number of nodes: {len(G_similarity.nodes):,}\")\n",
    "    print(f\"  Number of edges: {len(G_similarity.edges):,}\")\n",
    "    print(f\"  Number of connected components: {nx.number_connected_components(G_similarity)}\")\n",
    "    if len(G_similarity.nodes) > 0:\n",
    "        print(f\"  Average clustering coefficient: {nx.average_clustering(G_similarity):.3f}\")\n",
    "        print(f\"  Density: {nx.density(G_similarity):.4f}\")\n",
    "else:\n",
    "    print(\"No graph to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Find Nearest Neighbors\n",
    "\n",
    "For each model, find its architecturally most similar neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest neighbors for each model\n",
    "print(\"Finding nearest neighbors...\")\n",
    "\n",
    "nearest_neighbors = []\n",
    "n_show = min(20, len(df_sample))  # Show top 20 models\n",
    "\n",
    "for i in range(n_show):\n",
    "    model_id = df_sample.iloc[i]['modelId']\n",
    "    distances = similarity_matrix[i, :]\n",
    "    \n",
    "    # Get top 5 nearest neighbors (excluding self)\n",
    "    nearest_indices = np.argsort(distances)[1:6]\n",
    "    \n",
    "    neighbors_info = []\n",
    "    for j in nearest_indices:\n",
    "        neighbor_id = df_sample.iloc[j]['modelId']\n",
    "        distance = distances[j]\n",
    "        similarity = 1 - distance\n",
    "        neighbors_info.append({\n",
    "            'neighbor': neighbor_id,\n",
    "            'distance': distance,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "    \n",
    "    nearest_neighbors.append({\n",
    "        'model': model_id,\n",
    "        'neighbors': neighbors_info\n",
    "    })\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nSample nearest neighbors (showing first 5 models):\")\n",
    "for i, nn_info in enumerate(nearest_neighbors[:5]):\n",
    "    print(f\"\\n{i+1}. {nn_info['model']}\")\n",
    "    for j, neighbor in enumerate(nn_info['neighbors'][:3]):\n",
    "        print(f\"   {j+1}. {neighbor['neighbor']} (similarity: {neighbor['similarity']:.3f}, distance: {neighbor['distance']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare Similarity Metrics\n",
    "\n",
    "Compare Gower distance with other similarity metrics (L2, L1, Cosine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different similarity metrics on a sample\n",
    "print(\"Comparing similarity metrics...\")\n",
    "\n",
    "# Sample pairs for comparison\n",
    "n_pairs = min(10, len(df_sample) // 2)\n",
    "comparison_pairs = [(i, i+1) for i in range(n_pairs)]\n",
    "\n",
    "metrics_comparison = []\n",
    "\n",
    "for i, j in comparison_pairs:\n",
    "    vec_i = df_sample.iloc[i][available_features]\n",
    "    vec_j = df_sample.iloc[j][available_features]\n",
    "    \n",
    "    # Extract numeric features only for L2/L1/Cosine\n",
    "    numeric_vec_i = vec_i[numeric_features].dropna()\n",
    "    numeric_vec_j = vec_j[numeric_features].dropna()\n",
    "    \n",
    "    # Common numeric features\n",
    "    common_numeric = numeric_vec_i.index.intersection(numeric_vec_j.index)\n",
    "    \n",
    "    if len(common_numeric) > 0:\n",
    "        vec_i_numeric = numeric_vec_i[common_numeric].astype(float)\n",
    "        vec_j_numeric = numeric_vec_j[common_numeric].astype(float)\n",
    "        \n",
    "        # Standardize for fair comparison\n",
    "        scaler = StandardScaler()\n",
    "        vec_i_scaled = scaler.fit_transform(vec_i_numeric.values.reshape(1, -1))[0]\n",
    "        vec_j_scaled = scaler.fit_transform(vec_j_numeric.values.reshape(1, -1))[0]\n",
    "        \n",
    "        # Compute metrics\n",
    "        gower_dist = gower_distance(vec_i, vec_j, numeric_features, categorical_features, boolean_feature_list)\n",
    "        l2_dist = np.linalg.norm(vec_i_scaled - vec_j_scaled)\n",
    "        l1_dist = np.sum(np.abs(vec_i_scaled - vec_j_scaled))\n",
    "        \n",
    "        # Cosine similarity (1 - cosine distance)\n",
    "        norm_i = np.linalg.norm(vec_i_scaled)\n",
    "        norm_j = np.linalg.norm(vec_j_scaled)\n",
    "        if norm_i > 0 and norm_j > 0:\n",
    "            cosine_sim = np.dot(vec_i_scaled, vec_j_scaled) / (norm_i * norm_j)\n",
    "            cosine_dist = 1 - cosine_sim\n",
    "        else:\n",
    "            cosine_dist = 1.0\n",
    "        \n",
    "        metrics_comparison.append({\n",
    "            'pair': f\"{df_sample.iloc[i]['modelId']} vs {df_sample.iloc[j]['modelId']}\",\n",
    "            'gower': gower_dist,\n",
    "            'l2': l2_dist,\n",
    "            'l1': l1_dist,\n",
    "            'cosine': cosine_dist\n",
    "        })\n",
    "\n",
    "if len(metrics_comparison) > 0:\n",
    "    df_metrics = pd.DataFrame(metrics_comparison)\n",
    "    print(f\"\\n✓ Compared {len(df_metrics)} pairs\")\n",
    "    print(f\"\\nMetric comparison (mean distances):\")\n",
    "    print(f\"  Gower: {df_metrics['gower'].mean():.3f}\")\n",
    "    print(f\"  L2 (Euclidean): {df_metrics['l2'].mean():.3f}\")\n",
    "    print(f\"  L1 (Manhattan): {df_metrics['l1'].mean():.3f}\")\n",
    "    print(f\"  Cosine distance: {df_metrics['cosine'].mean():.3f}\")\n",
    "    \n",
    "    # Visualize comparison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    x_pos = np.arange(len(df_metrics))\n",
    "    width = 0.2\n",
    "    \n",
    "    ax.bar(x_pos - 1.5*width, df_metrics['gower'], width, label='Gower', alpha=0.7)\n",
    "    ax.bar(x_pos - 0.5*width, df_metrics['l2'], width, label='L2', alpha=0.7)\n",
    "    ax.bar(x_pos + 0.5*width, df_metrics['l1'], width, label='L1', alpha=0.7)\n",
    "    ax.bar(x_pos + 1.5*width, df_metrics['cosine'], width, label='Cosine', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Model Pair', fontsize=11)\n",
    "    ax.set_ylabel('Distance', fontsize=11)\n",
    "    ax.set_title('Similarity Metric Comparison', fontsize=13)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([f\"Pair {i+1}\" for i in range(len(df_metrics))], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/similarity_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid pairs for metric comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics\n",
    "\n",
    "Summary of similarity analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIG SIMILARITY ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Total models analyzed: {len(df_sample):,}\")\n",
    "print(f\"  Features used: {len(available_features)}\")\n",
    "print(f\"    - Numeric: {len(numeric_features)}\")\n",
    "print(f\"    - Categorical: {len(categorical_features)}\")\n",
    "print(f\"    - Boolean: {len(boolean_feature_list)}\")\n",
    "\n",
    "print(f\"\\nSimilarity Matrix:\")\n",
    "print(f\"  Size: {similarity_matrix.shape[0]}x{similarity_matrix.shape[1]}\")\n",
    "print(f\"  Mean distance: {similarity_matrix[similarity_matrix > 0].mean():.3f}\")\n",
    "print(f\"  Median distance: {np.median(similarity_matrix[similarity_matrix > 0]):.3f}\")\n",
    "print(f\"  Min distance: {similarity_matrix[similarity_matrix > 0].min():.3f}\")\n",
    "print(f\"  Max distance: {similarity_matrix[similarity_matrix > 0].max():.3f}\")\n",
    "\n",
    "print(f\"\\nSimilarity Graph:\")\n",
    "print(f\"  Nodes: {len(G_similarity.nodes):,}\")\n",
    "print(f\"  Edges: {len(G_similarity.edges):,}\")\n",
    "print(f\"  Connected components: {nx.number_connected_components(G_similarity)}\")\n",
    "if len(G_similarity.nodes) > 0:\n",
    "    print(f\"  Average degree: {2*len(G_similarity.edges)/len(G_similarity.nodes):.2f}\")\n",
    "    print(f\"  Density: {nx.density(G_similarity):.4f}\")\n",
    "    print(f\"  Average clustering: {nx.average_clustering(G_similarity):.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Optional: Config Drift Analysis\n",
    "\n",
    "**Goal**: Measure how architecture drifts along family tree edges, replicating the trait drift analysis from the AI Ecosystem paper.\n",
    "\n",
    "**Key Questions**:\n",
    "- Do fine-tunes preserve architecture?\n",
    "- Which families mutate architecture the most?\n",
    "- What is the distribution of config drift within vs between families?\n",
    "\n",
    "**Note**: This section requires family graph data. It will gracefully skip if graph files are not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load family graph to analyze parent-child relationships\n",
    "import pickle\n",
    "\n",
    "# Try to load the family graph\n",
    "G_family = None\n",
    "try:\n",
    "    graph_paths = [\n",
    "        '../data/ai_ecosystem_graph_finetune_fulljson.pkl',\n",
    "        '../data/ai_ecosystem_graph_nomerges.pkl',\n",
    "        '../data/ai_ecosystem_graph.pkl'\n",
    "    ]\n",
    "    for path in graph_paths:\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                G_family = pickle.load(f)\n",
    "            print(f\"✓ Loaded family graph from {path}\")\n",
    "            print(f\"  Nodes: {len(G_family.nodes):,}\")\n",
    "            print(f\"  Edges: {len(G_family.edges):,}\")\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Could not load graph: {e}\")\n",
    "    print(\"Will compute drift from parent_model columns in dataframe\")\n",
    "\n",
    "# Compute config drift for parent-child pairs\n",
    "if G_family is not None:\n",
    "    # Extract parent-child pairs from graph\n",
    "    parent_child_pairs = []\n",
    "    for parent, child in G_family.edges():\n",
    "        if parent in df['modelId'].values and child in df['modelId'].values:\n",
    "            parent_child_pairs.append((parent, child))\n",
    "    \n",
    "    print(f\"Found {len(parent_child_pairs):,} parent-child pairs in graph\")\n",
    "else:\n",
    "    # Fallback: use parent_model columns from dataframe\n",
    "    print(\"Using parent_model columns from dataframe\")\n",
    "    parent_child_pairs = []\n",
    "    \n",
    "    # Check for parent columns\n",
    "    parent_cols = ['parent_model', 'finetune_parent', 'quantized_parent', 'adapter_parent', 'merge_parent']\n",
    "    available_parent_cols = [col for col in parent_cols if col in df.columns]\n",
    "    \n",
    "    if len(available_parent_cols) > 0:\n",
    "        for idx, row in df.iterrows():\n",
    "            model_id = row['modelId']\n",
    "            for col in available_parent_cols:\n",
    "                if pd.notna(row[col]):\n",
    "                    try:\n",
    "                        parents = eval(row[col]) if isinstance(row[col], str) else row[col]\n",
    "                        if isinstance(parents, list):\n",
    "                            for parent in parents:\n",
    "                                if parent in df['modelId'].values:\n",
    "                                    parent_child_pairs.append((parent, model_id))\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"Found {len(parent_child_pairs):,} parent-child pairs from dataframe columns\")\n",
    "    else:\n",
    "        print(\"⚠ No parent columns found in dataframe\")\n",
    "\n",
    "# Sample pairs for analysis (if too many)\n",
    "MAX_PAIRS = 5000\n",
    "if len(parent_child_pairs) > MAX_PAIRS:\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    parent_child_pairs = random.sample(parent_child_pairs, MAX_PAIRS)\n",
    "    print(f\"Sampled {len(parent_child_pairs):,} pairs for analysis\")\n",
    "\n",
    "print(f\"\\nTotal parent-child pairs to analyze: {len(parent_child_pairs):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute config drift for each parent-child pair\n",
    "if len(parent_child_pairs) > 0:\n",
    "    print(\"Computing config drift for parent-child pairs...\")\n",
    "    \n",
    "    drift_data = []\n",
    "    for i, (parent_id, child_id) in enumerate(parent_child_pairs):\n",
    "        if i % 500 == 0 and i > 0:\n",
    "            print(f\"  Processed {i}/{len(parent_child_pairs)} pairs...\")\n",
    "        \n",
    "        # Get config vectors\n",
    "        parent_row = df[df['modelId'] == parent_id]\n",
    "        child_row = df[df['modelId'] == child_id]\n",
    "        \n",
    "        if len(parent_row) == 0 or len(child_row) == 0:\n",
    "            continue\n",
    "        \n",
    "        parent_vec = parent_row.iloc[0][available_features]\n",
    "        child_vec = child_row.iloc[0][available_features]\n",
    "        \n",
    "        # Compute Gower distance (drift)\n",
    "        drift = gower_distance(\n",
    "            parent_vec,\n",
    "            child_vec,\n",
    "            numeric_features,\n",
    "            categorical_features,\n",
    "            boolean_feature_list\n",
    "        )\n",
    "        \n",
    "        # Get family info if available\n",
    "        parent_family = parent_row.iloc[0].get('family', 'Unknown')\n",
    "        child_family = child_row.iloc[0].get('family', 'Unknown')\n",
    "        same_family = parent_family == child_family and parent_family != 'Unknown'\n",
    "        \n",
    "        drift_data.append({\n",
    "            'parent_id': parent_id,\n",
    "            'child_id': child_id,\n",
    "            'drift': drift,\n",
    "            'similarity': 1 - drift,\n",
    "            'parent_family': parent_family,\n",
    "            'child_family': child_family,\n",
    "            'same_family': same_family\n",
    "        })\n",
    "    \n",
    "    df_drift = pd.DataFrame(drift_data)\n",
    "    print(f\"\\n✓ Computed drift for {len(df_drift):,} parent-child pairs\")\n",
    "    if len(df_drift) > 0:\n",
    "        print(f\"  Mean drift: {df_drift['drift'].mean():.3f}\")\n",
    "        print(f\"  Median drift: {df_drift['drift'].median():.3f}\")\n",
    "    else:\n",
    "        print(\"  ⚠ No drift data computed - check parent-child pairs extraction\")\n",
    "else:\n",
    "    print(\"⚠ No parent-child pairs found - skipping drift analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize config drift distributions\n",
    "if 'df_drift' in locals() and len(df_drift) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Overall drift distribution\n",
    "    axes[0,0].hist(df_drift['drift'], bins=50, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "    median_drift = df_drift['drift'].median()\n",
    "    axes[0,0].axvline(median_drift, color='red', linestyle='--', linewidth=2, label=f'Median: {median_drift:.3f}')\n",
    "    axes[0,0].set_xlabel('Config Drift (Gower Distance)', fontsize=11)\n",
    "    axes[0,0].set_ylabel('Count', fontsize=11)\n",
    "    axes[0,0].set_title('Distribution of Config Drift Along Parent-Child Edges', fontsize=13)\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Within-family vs between-family drift\n",
    "    if df_drift['same_family'].sum() > 0:\n",
    "        within_family = df_drift[df_drift['same_family'] == True]['drift']\n",
    "        between_family = df_drift[df_drift['same_family'] == False]['drift']\n",
    "        \n",
    "        axes[0,1].hist([within_family, between_family], bins=30, label=['Within Family', 'Between Families'], \n",
    "                      alpha=0.7, color=['seagreen', 'coral'], edgecolor='white')\n",
    "        axes[0,1].set_xlabel('Config Drift', fontsize=11)\n",
    "        axes[0,1].set_ylabel('Count', fontsize=11)\n",
    "        axes[0,1].set_title('Config Drift: Within vs Between Families', fontsize=13)\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        print(f\"\\nWithin-family drift: mean={within_family.mean():.3f}, median={within_family.median():.3f}\")\n",
    "        print(f\"Between-family drift: mean={between_family.mean():.3f}, median={between_family.median():.3f}\")\n",
    "    \n",
    "    # 3. Drift by family (top families)\n",
    "    if 'parent_family' in df_drift.columns:\n",
    "        family_drift = df_drift.groupby('parent_family')['drift'].agg(['mean', 'median', 'count']).sort_values('count', ascending=False)\n",
    "        top_families = family_drift.head(10)\n",
    "        \n",
    "        if len(top_families) > 0:\n",
    "            x_pos = np.arange(len(top_families))\n",
    "            width = 0.35\n",
    "            axes[1,0].bar(x_pos - width/2, top_families['mean'], width, label='Mean', color='steelblue', alpha=0.7)\n",
    "            axes[1,0].bar(x_pos + width/2, top_families['median'], width, label='Median', color='coral', alpha=0.7)\n",
    "            axes[1,0].set_xticks(x_pos)\n",
    "            axes[1,0].set_xticklabels(top_families.index, rotation=45, ha='right')\n",
    "            axes[1,0].set_ylabel('Config Drift', fontsize=11)\n",
    "            axes[1,0].set_title('Config Drift by Family (Top 10)', fontsize=13)\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Cumulative drift distribution\n",
    "    sorted_drift = np.sort(df_drift['drift'])\n",
    "    cumulative = np.arange(1, len(sorted_drift) + 1) / len(sorted_drift)\n",
    "    axes[1,1].plot(sorted_drift, cumulative, linewidth=2, color='purple')\n",
    "    axes[1,1].axvline(df_drift['drift'].median(), color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    axes[1,1].set_xlabel('Config Drift', fontsize=11)\n",
    "    axes[1,1].set_ylabel('Cumulative Fraction', fontsize=11)\n",
    "    axes[1,1].set_title('Cumulative Distribution of Config Drift', fontsize=13)\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/config_drift_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save drift data\n",
    "    df_drift.to_csv('config_drift_pairs.csv', index=False)\n",
    "    print(\"\\n✓ Drift data saved to config_drift_pairs.csv\")\n",
    "else:\n",
    "    print(\"No drift data to visualize\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
