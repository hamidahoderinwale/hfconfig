{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Config Similarity Basics\n",
        "\n",
        "**Goal**: Core similarity computation and graph construction for config-based architectural similarity.\n",
        "\n",
        "**Key Questions**:\n",
        "1. Which models are architecturally similar?\n",
        "2. How do models cluster in architecture space?\n",
        "3. What are the nearest neighbors in architecture space?\n",
        "4. How do different similarity metrics compare?\n",
        "\n",
        "**Contents**:\n",
        "- Feature preparation and categorization\n",
        "- Gower distance implementation (handles mixed data types)\n",
        "- Similarity matrix computation\n",
        "- Similarity graph construction\n",
        "- Graph visualization and statistics\n",
        "- Nearest neighbors analysis\n",
        "- Similarity metrics comparison (Gower, L2, L1, Cosine)\n",
        "\n",
        "**This is the foundational notebook** - other notebooks build on these utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Style matching main repo\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config data\n",
        "df = pd.read_csv('data/model_configs_expanded.csv', low_memory=False)\n",
        "print(f\"Loaded {len(df):,} models with config.json\")\n",
        "print(f\"Total columns: {len(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prepare Config Features for Similarity Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define feature groups for similarity computation\n",
        "\n",
        "# Core architecture features (high weight)\n",
        "architecture_features = [\n",
        "    'config_model_type',\n",
        "    'config_hidden_size',\n",
        "    'config_num_hidden_layers',\n",
        "    'config_num_attention_heads',\n",
        "    'config_intermediate_size'\n",
        "]\n",
        "\n",
        "# Capacity features (medium weight)\n",
        "capacity_features = [\n",
        "    'config_vocab_size',\n",
        "    'config_max_position_embeddings',\n",
        "    'config_num_key_value_heads'\n",
        "]\n",
        "\n",
        "# Precision/compute features (lower weight)\n",
        "precision_features = [\n",
        "    'config_torch_dtype',\n",
        "    'config_rope_theta',\n",
        "    'config_rope_scaling_type'\n",
        "]\n",
        "\n",
        "# Boolean flags (low weight)\n",
        "boolean_features = [\n",
        "    'uses_moe',\n",
        "    'uses_gqa',\n",
        "    'uses_rope',\n",
        "    'uses_quantization'\n",
        "]\n",
        "\n",
        "# All features for similarity\n",
        "all_features = architecture_features + capacity_features + precision_features + boolean_features\n",
        "\n",
        "# Filter to features that exist in dataframe\n",
        "available_features = [f for f in all_features if f in df.columns]\n",
        "print(f\"Available features for similarity: {len(available_features)}\")\n",
        "print(f\"Features: {available_features[:10]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Implement Gower Distance (Recommended for Mixed Data Types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gower_distance(x, y, numeric_cols, categorical_cols, boolean_cols):\n",
        "    \"\"\"\n",
        "    Compute Gower distance between two config vectors.\n",
        "    \n",
        "    For numeric: normalized absolute difference\n",
        "    For categorical: 0 if same, 1 if different\n",
        "    For boolean: 0 if same, 1 if different\n",
        "    Missing values: ignored in that dimension\n",
        "    \"\"\"\n",
        "    distance = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    # Numeric features: normalized absolute difference\n",
        "    for col in numeric_cols:\n",
        "        if col in x.index and col in y.index:\n",
        "            x_val = x[col]\n",
        "            y_val = y[col]\n",
        "            \n",
        "            # Skip if either is missing\n",
        "            if pd.isna(x_val) or pd.isna(y_val):\n",
        "                continue\n",
        "            \n",
        "            # Convert to numeric\n",
        "            try:\n",
        "                x_num = float(x_val)\n",
        "                y_num = float(y_val)\n",
        "                \n",
        "                # Normalized difference (using max-min normalization)\n",
        "                # For now, use absolute difference normalized by max value\n",
        "                max_val = max(abs(x_num), abs(y_num))\n",
        "                if max_val > 0:\n",
        "                    distance += abs(x_num - y_num) / max_val\n",
        "                else:\n",
        "                    distance += 0  # Both are 0\n",
        "                count += 1\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "    \n",
        "    # Categorical features: 0 if same, 1 if different\n",
        "    for col in categorical_cols:\n",
        "        if col in x.index and col in y.index:\n",
        "            x_val = x[col]\n",
        "            y_val = y[col]\n",
        "            \n",
        "            # Skip if either is missing\n",
        "            if pd.isna(x_val) or pd.isna(y_val):\n",
        "                continue\n",
        "            \n",
        "            # Compare as strings\n",
        "            if str(x_val) != str(y_val):\n",
        "                distance += 1.0\n",
        "            count += 1\n",
        "    \n",
        "    # Boolean features: 0 if same, 1 if different\n",
        "    for col in boolean_cols:\n",
        "        if col in x.index and col in y.index:\n",
        "            x_val = x[col]\n",
        "            y_val = y[col]\n",
        "            \n",
        "            # Skip if either is missing\n",
        "            if pd.isna(x_val) or pd.isna(y_val):\n",
        "                continue\n",
        "            \n",
        "            # Normalize boolean values\n",
        "            x_bool = bool(x_val) if not pd.isna(x_val) else False\n",
        "            y_bool = bool(y_val) if not pd.isna(y_val) else False\n",
        "            \n",
        "            if x_bool != y_bool:\n",
        "                distance += 1.0\n",
        "            count += 1\n",
        "    \n",
        "    # Return average distance (0 = identical, 1 = completely different)\n",
        "    if count > 0:\n",
        "        return distance / count\n",
        "    else:\n",
        "        return 1.0  # No common features = maximum distance\n",
        "\n",
        "print(\"Gower distance function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Categorize Features by Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorize features by data type\n",
        "numeric_features = []\n",
        "categorical_features = []\n",
        "boolean_feature_list = []\n",
        "\n",
        "for feat in available_features:\n",
        "    if feat in df.columns:\n",
        "        # Check data type\n",
        "        sample_values = df[feat].dropna().head(100)\n",
        "        \n",
        "        if len(sample_values) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Try to convert to numeric\n",
        "        try:\n",
        "            pd.to_numeric(sample_values, errors='raise')\n",
        "            numeric_features.append(feat)\n",
        "        except (ValueError, TypeError):\n",
        "            # Check if boolean-like\n",
        "            unique_vals = sample_values.unique()\n",
        "            if len(unique_vals) <= 2 and set(str(v).lower() for v in unique_vals).issubset({'true', 'false', '1', '0', 'yes', 'no', 'nan'}):\n",
        "                boolean_feature_list.append(feat)\n",
        "            else:\n",
        "                categorical_features.append(feat)\n",
        "\n",
        "print(f\"Numeric features: {len(numeric_features)}\")\n",
        "print(f\"  {numeric_features[:5]}...\")\n",
        "print(f\"\\nCategorical features: {len(categorical_features)}\")\n",
        "print(f\"  {categorical_features[:5]}...\")\n",
        "print(f\"\\nBoolean features: {len(boolean_feature_list)}\")\n",
        "print(f\"  {boolean_feature_list}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compute Similarity Matrix (Sample for MVP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For MVP, sample a subset of models to make computation feasible\n",
        "# Focus on models with complete config data\n",
        "\n",
        "# Filter to models with at least some key features\n",
        "key_features = ['config_hidden_size', 'config_num_hidden_layers', 'config_model_type']\n",
        "df_complete = df[df[key_features].notna().any(axis=1)].copy()\n",
        "\n",
        "# Sample for MVP (can increase later)\n",
        "SAMPLE_SIZE = 1000  # Start with 1000 models for MVP\n",
        "if len(df_complete) > SAMPLE_SIZE:\n",
        "    # Stratified sample by family if available\n",
        "    if 'family' in df_complete.columns:\n",
        "        df_sample = df_complete.groupby('family', group_keys=False).apply(\n",
        "            lambda x: x.sample(min(len(x), SAMPLE_SIZE // len(df_complete['family'].unique()) + 1))\n",
        "        ).head(SAMPLE_SIZE)\n",
        "    else:\n",
        "        df_sample = df_complete.sample(n=SAMPLE_SIZE, random_state=42)\n",
        "else:\n",
        "    df_sample = df_complete.copy()\n",
        "\n",
        "print(f\"Sampling {len(df_sample):,} models for similarity computation\")\n",
        "print(f\"This will compute {len(df_sample) * (len(df_sample) - 1) // 2:,} pairwise distances\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Architecture Phylogeny: Config Drift Along Parent-Child Edges\n",
        "\n",
        "**Goal**: Measure how architecture drifts along family tree edges, replicating the trait drift analysis from the AI Ecosystem paper.\n",
        "\n",
        "**Key Questions**:\n",
        "- Do fine-tunes preserve architecture?\n",
        "- Which families mutate architecture the most?\n",
        "- What is the distribution of config drift within vs between families?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load family graph to analyze parent-child relationships\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Try to load the family graph\n",
        "G_family = None\n",
        "try:\n",
        "    graph_paths = [\n",
        "        'data/ai_ecosystem_graph_finetune_fulljson.pkl',\n",
        "        'data/ai_ecosystem_graph_nomerges.pkl',\n",
        "        'data/ai_ecosystem_graph.pkl'\n",
        "    ]\n",
        "    for path in graph_paths:\n",
        "        if os.path.exists(path):\n",
        "            with open(path, 'rb') as f:\n",
        "                G_family = pickle.load(f)\n",
        "            print(f\"Loaded family graph from {path}\")\n",
        "            print(f\"  Nodes: {len(G_family.nodes):,}\")\n",
        "            print(f\"  Edges: {len(G_family.edges):,}\")\n",
        "            break\n",
        "except Exception as e:\n",
        "    print(f\"Could not load graph: {e}\")\n",
        "    print(\"Will compute drift from parent_model columns in dataframe\")\n",
        "\n",
        "# Compute config drift for parent-child pairs\n",
        "if G_family is not None:\n",
        "    # Extract parent-child pairs from graph\n",
        "    parent_child_pairs = []\n",
        "    for parent, child in G_family.edges():\n",
        "        if parent in df['modelId'].values and child in df['modelId'].values:\n",
        "            parent_child_pairs.append((parent, child))\n",
        "    \n",
        "    print(f\"Found {len(parent_child_pairs):,} parent-child pairs in graph\")\n",
        "else:\n",
        "    # Fallback: use parent_model columns from dataframe\n",
        "    print(\"Using parent_model columns from dataframe\")\n",
        "    parent_child_pairs = []\n",
        "    \n",
        "    # Check for parent columns\n",
        "    parent_cols = ['parent_model', 'finetune_parent', 'quantized_parent', 'adapter_parent', 'merge_parent']\n",
        "    available_parent_cols = [col for col in parent_cols if col in df.columns]\n",
        "    \n",
        "    if len(available_parent_cols) > 0:\n",
        "        for idx, row in df.iterrows():\n",
        "            model_id = row['modelId']\n",
        "            for col in available_parent_cols:\n",
        "                if pd.notna(row[col]):\n",
        "                    try:\n",
        "                        parents = eval(row[col]) if isinstance(row[col], str) else row[col]\n",
        "                        if isinstance(parents, list):\n",
        "                            for parent in parents:\n",
        "                                if parent in df['modelId'].values:\n",
        "                                    parent_child_pairs.append((parent, model_id))\n",
        "                    except:\n",
        "                        continue\n",
        "        \n",
        "        print(f\"Found {len(parent_child_pairs):,} parent-child pairs from dataframe columns\")\n",
        "\n",
        "# Sample pairs for analysis (if too many)\n",
        "MAX_PAIRS = 5000\n",
        "if len(parent_child_pairs) > MAX_PAIRS:\n",
        "    import random\n",
        "    parent_child_pairs = random.sample(parent_child_pairs, MAX_PAIRS)\n",
        "    print(f\"Sampled {len(parent_child_pairs):,} pairs for analysis\")\n",
        "\n",
        "print(f\"\\\\nTotal parent-child pairs to analyze: {len(parent_child_pairs):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute config drift for each parent-child pair\n",
        "print(\"Computing config drift for parent-child pairs...\")\n",
        "\n",
        "drift_data = []\n",
        "for i, (parent_id, child_id) in enumerate(parent_child_pairs):\n",
        "    if i % 500 == 0 and i > 0:\n",
        "        print(f\"  Processed {i}/{len(parent_child_pairs)} pairs...\")\n",
        "    \n",
        "    # Get config vectors\n",
        "    parent_row = df[df['modelId'] == parent_id]\n",
        "    child_row = df[df['modelId'] == child_id]\n",
        "    \n",
        "    if len(parent_row) == 0 or len(child_row) == 0:\n",
        "        continue\n",
        "    \n",
        "    parent_vec = parent_row.iloc[0][available_features]\n",
        "    child_vec = child_row.iloc[0][available_features]\n",
        "    \n",
        "    # Compute Gower distance (drift)\n",
        "    drift = gower_distance(\n",
        "        parent_vec,\n",
        "        child_vec,\n",
        "        numeric_features,\n",
        "        categorical_features,\n",
        "        boolean_feature_list\n",
        "    )\n",
        "    \n",
        "    # Get family info if available\n",
        "    parent_family = parent_row.iloc[0].get('family', 'Unknown')\n",
        "    child_family = child_row.iloc[0].get('family', 'Unknown')\n",
        "    same_family = parent_family == child_family and parent_family != 'Unknown'\n",
        "    \n",
        "    drift_data.append({\n",
        "        'parent_id': parent_id,\n",
        "        'child_id': child_id,\n",
        "        'drift': drift,\n",
        "        'similarity': 1 - drift,\n",
        "        'parent_family': parent_family,\n",
        "        'child_family': child_family,\n",
        "        'same_family': same_family\n",
        "    })\n",
        "\n",
        "df_drift = pd.DataFrame(drift_data)\n",
        "print(f\"\\\\n✓ Computed drift for {len(df_drift):,} parent-child pairs\")\n",
        "print(f\"  Mean drift: {df_drift['drift'].mean():.3f}\")\n",
        "print(f\"  Median drift: {df_drift['drift'].median():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize config drift distributions\n",
        "if len(df_drift) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Overall drift distribution\n",
        "    axes[0,0].hist(df_drift['drift'], bins=50, color='steelblue', alpha=0.7, edgecolor='white')\n",
        "    axes[0,0].axvline(df_drift['drift'].median(), color='red', linestyle='--', linewidth=2, label=f'Median: {df_drift[\\\"drift\\\"].median():.3f}')\n",
        "    axes[0,0].set_xlabel('Config Drift (Gower Distance)', fontsize=11)\n",
        "    axes[0,0].set_ylabel('Count', fontsize=11)\n",
        "    axes[0,0].set_title('Distribution of Config Drift Along Parent-Child Edges', fontsize=13)\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # 2. Within-family vs between-family drift\n",
        "    if df_drift['same_family'].sum() > 0:\n",
        "        within_family = df_drift[df_drift['same_family'] == True]['drift']\n",
        "        between_family = df_drift[df_drift['same_family'] == False]['drift']\n",
        "        \n",
        "        axes[0,1].hist([within_family, between_family], bins=30, label=['Within Family', 'Between Families'], \n",
        "                      alpha=0.7, color=['seagreen', 'coral'], edgecolor='white')\n",
        "        axes[0,1].set_xlabel('Config Drift', fontsize=11)\n",
        "        axes[0,1].set_ylabel('Count', fontsize=11)\n",
        "        axes[0,1].set_title('Config Drift: Within vs Between Families', fontsize=13)\n",
        "        axes[0,1].legend()\n",
        "        axes[0,1].grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        print(f\"\\\\nWithin-family drift: mean={within_family.mean():.3f}, median={within_family.median():.3f}\")\n",
        "        print(f\"Between-family drift: mean={between_family.mean():.3f}, median={between_family.median():.3f}\")\n",
        "    \n",
        "    # 3. Drift by family (top families)\n",
        "    if 'parent_family' in df_drift.columns:\n",
        "        family_drift = df_drift.groupby('parent_family')['drift'].agg(['mean', 'median', 'count']).sort_values('count', ascending=False)\n",
        "        top_families = family_drift.head(10)\n",
        "        \n",
        "        x_pos = np.arange(len(top_families))\n",
        "        width = 0.35\n",
        "        axes[1,0].bar(x_pos - width/2, top_families['mean'], width, label='Mean', color='steelblue', alpha=0.7)\n",
        "        axes[1,0].bar(x_pos + width/2, top_families['median'], width, label='Median', color='coral', alpha=0.7)\n",
        "        axes[1,0].set_xticks(x_pos)\n",
        "        axes[1,0].set_xticklabels(top_families.index, rotation=45, ha='right')\n",
        "        axes[1,0].set_ylabel('Config Drift', fontsize=11)\n",
        "        axes[1,0].set_title('Config Drift by Family (Top 10)', fontsize=13)\n",
        "        axes[1,0].legend()\n",
        "        axes[1,0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # 4. Cumulative drift distribution\n",
        "    sorted_drift = np.sort(df_drift['drift'])\n",
        "    cumulative = np.arange(1, len(sorted_drift) + 1) / len(sorted_drift)\n",
        "    axes[1,1].plot(sorted_drift, cumulative, linewidth=2, color='purple')\n",
        "    axes[1,1].axvline(df_drift['drift'].median(), color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
        "    axes[1,1].set_xlabel('Config Drift', fontsize=11)\n",
        "    axes[1,1].set_ylabel('Cumulative Fraction', fontsize=11)\n",
        "    axes[1,1].set_title('Cumulative Distribution of Config Drift', fontsize=13)\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('figures/config_drift_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Save drift data\n",
        "    df_drift.to_csv('config_drift_pairs.csv', index=False)\n",
        "    print(\"\\\\n✓ Drift data saved to config_drift_pairs.csv\")\n",
        "else:\n",
        "    print(\"No drift data to visualize\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
