{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention & Context Length Analysis\n",
    "\n",
    "**Goal**: Deep dive into attention mechanisms and context length configurations.\n",
    "\n",
    "**Key Questions**:\n",
    "1. How has context length evolved across the ecosystem?\n",
    "2. What GQA ratios are most common?\n",
    "3. What RoPE configurations are being used?\n",
    "4. How do head dimensions vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style matching main repo\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/model_configs_expanded.csv', low_memory=False)\n",
    "\n",
    "# Convert boolean columns\n",
    "bool_cols = [c for c in df.columns if c.startswith('is_') or c.startswith('uses_')]\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].map({'True': True, 'False': False, True: True, False: False})\n",
    "\n",
    "print(f\"Total models: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Context Length Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric first\n",
    "context = pd.to_numeric(df['config_max_position_embeddings'], errors='coerce').dropna()\n",
    "\n",
    "# Define context length categories\n",
    "def categorize_context(x):\n",
    "    if pd.isna(x):\n",
    "        return 'unknown'\n",
    "    x = float(x)\n",
    "    if x <= 512:\n",
    "        return '512 or less'\n",
    "    elif x <= 2048:\n",
    "        return '513-2K'\n",
    "    elif x <= 4096:\n",
    "        return '2K-4K'\n",
    "    elif x <= 8192:\n",
    "        return '4K-8K'\n",
    "    elif x <= 32768:\n",
    "        return '8K-32K'\n",
    "    elif x <= 131072:\n",
    "        return '32K-128K'\n",
    "    else:\n",
    "        return '128K+'\n",
    "\n",
    "context_cats = context.apply(categorize_context)\n",
    "cat_order = ['512 or less', '513-2K', '2K-4K', '4K-8K', '8K-32K', '32K-128K', '128K+']\n",
    "context_cat_counts = context_cats.value_counts().reindex(cat_order).fillna(0).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Bar chart of categories\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(cat_order)))\n",
    "bars = ax.bar(cat_order, context_cat_counts.values, color=colors)\n",
    "ax.set_xlabel('Context Length Category')\n",
    "ax.set_ylabel('Number of Models')\n",
    "ax.set_title('Context Length Distribution by Category', fontsize=13)\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "# Add percentage labels\n",
    "total = context_cat_counts.sum()\n",
    "for bar, val in zip(bars, context_cat_counts.values):\n",
    "    pct = val / total * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 20, \n",
    "                 f'{pct:.1f}%', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/context_length_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nContext length statistics:\")\n",
    "print(f\"  Min: {context.min():,.0f}\")\n",
    "print(f\"  Max: {context.max():,.0f}\")\n",
    "print(f\"  Median: {context.median():,.0f}\")\n",
    "print(f\"  Mean: {context.mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GQA (Grouped Query Attention) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to models with GQA\n",
    "df_gqa = df[df['uses_gqa'] == True].copy()\n",
    "gqa_count = len(df_gqa)\n",
    "non_gqa_count = len(df) - gqa_count\n",
    "\n",
    "print(f\"Models with GQA: {gqa_count:,} ({gqa_count/len(df)*100:.1f}%)\")\n",
    "print(f\"Models without GQA: {non_gqa_count:,} ({non_gqa_count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GQA Ratio analysis\n",
    "gqa_ratio = pd.to_numeric(df_gqa['config_gqa_ratio'], errors='coerce').dropna()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution of GQA ratios\n",
    "ratio_counts = gqa_ratio.value_counts().sort_index().head(20)\n",
    "axes[0].bar(range(len(ratio_counts)), ratio_counts.values, color='seagreen', alpha=0.8)\n",
    "axes[0].set_xticks(range(len(ratio_counts)))\n",
    "axes[0].set_xticklabels([f'{float(r):.1f}' for r in ratio_counts.index], rotation=45)\n",
    "axes[0].set_xlabel('GQA Ratio (num_heads / num_kv_heads)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('GQA Ratio Distribution', fontsize=13)\n",
    "\n",
    "# Common ratios as pie chart\n",
    "common_ratios = gqa_ratio.value_counts().head(5)\n",
    "colors_pie = plt.cm.Set2(np.linspace(0, 1, len(common_ratios)))\n",
    "axes[1].pie(common_ratios.values, labels=[f'{float(r):.0f}:1' for r in common_ratios.index],\n",
    "            autopct='%1.1f%%', colors=colors_pie)\n",
    "axes[1].set_title('Most Common GQA Ratios', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/gqa_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost common GQA ratios:\")\n",
    "for ratio, count in gqa_ratio.value_counts().head(10).items():\n",
    "    pct = count / len(gqa_ratio) * 100\n",
    "    print(f\"  {float(ratio):.1f}:1 â†’ {count:,} models ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RoPE (Rotary Position Embedding) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE adoption\n",
    "rope_count = (df['uses_rope'] == True).sum()\n",
    "print(f\"Models using RoPE: {rope_count:,} ({rope_count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE Theta analysis\n",
    "rope_theta = df['config_rope_theta'].dropna()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Log-scale histogram\n",
    "axes[0].hist(rope_theta, bins=50, color='navy', alpha=0.7, edgecolor='white')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('RoPE Theta (log scale)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('RoPE Theta Distribution', fontsize=13)\n",
    "\n",
    "# Most common theta values\n",
    "theta_counts = rope_theta.value_counts().head(10)\n",
    "labels = [f'{t:.0e}' if t >= 1e6 else f'{t:.0f}' for t in theta_counts.index]\n",
    "axes[1].barh(range(len(theta_counts)), theta_counts.values, color='navy', alpha=0.8)\n",
    "axes[1].set_yticks(range(len(theta_counts)))\n",
    "axes[1].set_yticklabels(labels)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Count')\n",
    "axes[1].set_title('Most Common RoPE Theta Values', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/rope_theta_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost common RoPE theta values:\")\n",
    "for theta, count in theta_counts.items():\n",
    "    print(f\"  {theta:,.0f} â†’ {count:,} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE Scaling Types\n",
    "rope_scaling = df['config_rope_scaling_type'].dropna()\n",
    "\n",
    "if len(rope_scaling) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    scaling_counts = rope_scaling.value_counts()\n",
    "    ax.barh(range(len(scaling_counts)), scaling_counts.values, color='darkblue', alpha=0.8)\n",
    "    ax.set_yticks(range(len(scaling_counts)))\n",
    "    ax.set_yticklabels(scaling_counts.index)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_title('RoPE Scaling Types', fontsize=13)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/rope_scaling_types.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nRoPE scaling type distribution:\")\n",
    "    print(scaling_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Head Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head dimension = hidden_size / num_attention_heads\n",
    "head_dim = df['config_head_dimension'].dropna()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution\n",
    "dim_counts = head_dim.value_counts().sort_index()\n",
    "# Focus on common values\n",
    "dim_common = dim_counts[dim_counts >= 5]\n",
    "axes[0].bar(dim_common.index.astype(int), dim_common.values, color='darkorange', alpha=0.8)\n",
    "axes[0].set_xlabel('Head Dimension')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Head Dimension Distribution', fontsize=13)\n",
    "\n",
    "# Top head dimensions\n",
    "top_dims = head_dim.value_counts().head(10)\n",
    "axes[1].pie(top_dims.values, labels=[f'{int(d)}' for d in top_dims.index],\n",
    "            autopct='%1.1f%%', colors=sns.color_palette('Oranges', len(top_dims)))\n",
    "axes[1].set_title('Most Common Head Dimensions', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/head_dimension_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost common head dimensions:\")\n",
    "for dim, count in top_dims.items():\n",
    "    pct = count / len(head_dim) * 100\n",
    "    print(f\"  {int(dim)} â†’ {count:,} models ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention Heads vs Hidden Size Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of hidden size vs num attention heads\n",
    "df_attn = df[['config_hidden_size', 'config_num_attention_heads', 'config_head_dimension']].dropna()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Hidden size vs Num heads (colored by head dim)\n",
    "scatter = axes[0].scatter(df_attn['config_num_attention_heads'], df_attn['config_hidden_size'],\n",
    "                          c=df_attn['config_head_dimension'], cmap='viridis', alpha=0.5, s=20)\n",
    "axes[0].set_xlabel('Number of Attention Heads')\n",
    "axes[0].set_ylabel('Hidden Size')\n",
    "axes[0].set_title('Hidden Size vs Attention Heads', fontsize=13)\n",
    "plt.colorbar(scatter, ax=axes[0], label='Head Dim')\n",
    "\n",
    "# Add reference lines for common head dimensions\n",
    "x_range = np.array([4, 128])\n",
    "for hd, color in [(64, 'red'), (128, 'blue')]:\n",
    "    axes[0].plot(x_range, x_range * hd, '--', color=color, alpha=0.5, label=f'head_dim={hd}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Head dim vs hidden size\n",
    "axes[1].scatter(df_attn['config_hidden_size'], df_attn['config_head_dimension'],\n",
    "                alpha=0.3, s=20, color='teal')\n",
    "axes[1].set_xlabel('Hidden Size')\n",
    "axes[1].set_ylabel('Head Dimension')\n",
    "axes[1].set_title('Head Dimension vs Hidden Size', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/attention_relationships.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Context Per Layer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context per layer = max_position_embeddings / num_hidden_layers\n",
    "ctx_per_layer = df['config_context_per_layer'].dropna()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.hist(ctx_per_layer, bins=50, color='mediumpurple', alpha=0.7, edgecolor='white')\n",
    "ax.axvline(ctx_per_layer.median(), color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Median: {ctx_per_layer.median():.0f}')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Context Per Layer (log scale)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Context Length Per Layer Distribution', fontsize=13)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/context_per_layer.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nContext per layer statistics:\")\n",
    "print(f\"  Min: {ctx_per_layer.min():.1f}\")\n",
    "print(f\"  Max: {ctx_per_layer.max():.1f}\")\n",
    "print(f\"  Median: {ctx_per_layer.median():.1f}\")\n",
    "print(f\"  Mean: {ctx_per_layer.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ATTENTION & CONTEXT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nðŸ“ CONTEXT LENGTH\")\n",
    "print(f\"   Median context: {context.median():,.0f}\")\n",
    "print(f\"   Range: [{context.min():,.0f}, {context.max():,.0f}]\")\n",
    "print(f\"   Models with 128K+ context: {(context >= 131072).sum():,}\")\n",
    "\n",
    "print(f\"\\nðŸ”„ GQA (Grouped Query Attention)\")\n",
    "print(f\"   Adoption rate: {gqa_count/len(df)*100:.1f}%\")\n",
    "print(f\"   Most common ratio: {gqa_ratio.mode().iloc[0] if len(gqa_ratio) > 0 else 'N/A'}:1\")\n",
    "\n",
    "print(f\"\\nðŸ”€ RoPE (Rotary Position Embedding)\")\n",
    "print(f\"   Adoption rate: {rope_count/len(df)*100:.1f}%\")\n",
    "print(f\"   Most common theta: {rope_theta.mode().iloc[0]:,.0f}\" if len(rope_theta) > 0 else \"N/A\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ HEAD DIMENSION\")\n",
    "print(f\"   Most common: {int(head_dim.mode().iloc[0])}\")\n",
    "print(f\"   Median: {head_dim.median():.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
